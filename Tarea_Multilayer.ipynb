{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train = True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train = False, transform=transforms.ToTensor(), download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_trains= 60000\n",
      "mnist_test= 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"mnist_trains= {}\".format(len(mnist_train)))\n",
    "print(\"mnist_test= {}\".format(len(mnist_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_iter = iter(train_loader)\n",
    "images, labels = data_train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "x = images.view(-1,784)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primera capa\n",
    "W = torch.randn(784, 500)/np.sqrt(784)\n",
    "W.requires_grad_()\n",
    "\n",
    "b = torch.zeros(500, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 500])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.matmul(x, W) + b\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0013, -0.0297,  0.0391, -0.3974, -0.1860,  0.5215, -0.1456, -0.2402,\n",
      "        -0.0107, -0.1730, -0.1208,  0.7346, -0.0102,  0.1563, -0.2614, -0.1441,\n",
      "        -0.2780, -0.1689,  0.4223, -0.3621, -0.2594,  0.3011, -0.2214, -0.1604,\n",
      "         0.3855,  0.1683, -0.2109, -0.0282,  0.0969, -0.1667, -0.2173, -0.5302,\n",
      "         0.3000, -0.4268,  0.2058,  0.7613,  0.1910,  0.4414,  0.3187,  0.1720,\n",
      "        -0.3731, -0.0073,  0.2081, -0.0557, -0.2437, -0.3361,  0.0448,  0.1827,\n",
      "        -0.1833, -0.2492,  0.2425, -0.2205,  0.1947, -0.1048,  0.5146,  0.4416,\n",
      "         0.6651,  0.2390,  0.1154, -0.5362, -0.4236,  0.1262,  0.2561, -0.6475,\n",
      "        -0.2107, -0.6937, -0.2809, -0.5106, -0.0745, -0.2346, -0.1408,  0.0428,\n",
      "         0.2968, -0.0063,  0.1072,  0.1070, -0.3303,  0.4765, -0.4390, -0.5816,\n",
      "         0.1913,  0.2218, -0.1343,  0.2528,  0.0812, -0.2155,  0.0760,  0.0047,\n",
      "         0.0028, -0.1660,  0.1236, -0.0424, -0.0307, -0.1529,  0.1658,  0.2493,\n",
      "         0.0780, -0.0941,  0.1663,  0.2134,  0.2088, -0.3398,  0.0208, -0.1810,\n",
      "        -0.4605, -0.5793,  0.0297, -0.0100,  0.1328,  0.0171,  0.2096,  0.2564,\n",
      "         0.4011,  0.8696,  0.0101,  0.3233,  0.0142,  0.0872, -0.3351, -0.0512,\n",
      "         0.0523, -0.0916, -0.0798, -0.1568,  0.2055, -0.0697,  0.0073,  0.3940,\n",
      "        -0.2503, -0.2837, -0.1484,  0.0236, -0.3446,  0.4544,  0.0970, -0.1763,\n",
      "         0.0483,  0.2462, -0.1637,  0.3812, -0.2196, -0.3306, -0.4149,  0.0990,\n",
      "        -0.0657, -0.5756,  0.0587, -0.1234, -0.3631, -0.0346,  0.0866,  0.3294,\n",
      "        -0.1092, -0.0640,  0.2210, -0.3857, -0.2052,  0.2608, -0.2463, -0.1586,\n",
      "         0.2601,  0.1181,  0.3393, -0.1625,  0.1738,  0.0241,  0.1337, -0.2412,\n",
      "         0.2692, -0.6088, -0.4010, -0.1326,  0.2022,  0.0985, -0.5266, -0.1617,\n",
      "        -0.0746,  0.5885,  0.1144,  0.0389,  0.1475,  0.4750,  0.0340,  0.2651,\n",
      "        -0.2714, -0.6237,  0.2482, -0.1913,  0.1709,  0.1799, -0.2476,  0.4391,\n",
      "        -0.4747,  0.1873,  0.0443,  0.2883, -0.0851,  0.0041, -0.4029,  0.1794,\n",
      "        -0.2993,  0.2390,  0.2895,  0.3153, -0.0349,  0.0361,  0.0350,  0.1885,\n",
      "         0.2127,  0.2277,  0.1453,  0.5372,  0.0902, -0.1370, -0.0452, -0.0612,\n",
      "         0.0397, -0.5805, -0.3660,  0.1828, -0.1929,  0.4819, -0.2023,  0.5418,\n",
      "        -0.2996,  0.2829, -0.1407,  0.3077,  0.1618,  0.2875,  0.0806,  0.1364,\n",
      "         0.3775, -0.2479, -0.0783, -0.0196,  0.0419,  0.1322, -0.2352, -0.6333,\n",
      "         0.4568,  0.1153, -0.0402, -0.0642,  0.3453,  0.2090, -0.1719,  0.1055,\n",
      "        -0.1247, -0.3097,  0.1132, -0.4702,  0.0315,  0.3874,  0.1551, -0.2206,\n",
      "        -0.3145, -0.0137, -0.1851, -0.3964,  0.4019, -0.0793,  0.2076,  0.4110,\n",
      "         0.2542,  0.5615, -0.5993,  0.3911,  0.0997,  0.1486, -0.2987,  0.5084,\n",
      "         0.0903, -0.0013, -0.2841, -0.0468, -0.7043, -0.0241, -0.0967, -0.2978,\n",
      "         0.2339, -0.2274, -0.3112,  0.0152, -0.0372,  0.5258,  0.1770,  0.3352,\n",
      "        -0.0449, -0.0829, -0.0583,  0.2157, -0.0319, -0.2521, -0.3195,  0.3262,\n",
      "        -0.4597,  0.0488, -0.2138, -0.2073,  0.1199,  0.5102,  0.2607,  0.3033,\n",
      "         0.2538, -0.0223, -0.4111, -0.1128,  0.1357, -0.1626, -0.1548, -0.2901,\n",
      "         0.2031, -0.1611,  0.0145, -0.0823,  0.3424,  0.1414,  0.0337,  0.6261,\n",
      "         0.0408,  0.1317, -0.1099,  0.0581, -0.0969,  0.2376,  0.0240,  0.0578,\n",
      "        -0.4687, -0.0780, -0.2012, -0.5929,  0.7267, -0.0151, -0.6801,  0.1846,\n",
      "        -0.5582, -0.2420,  0.7890, -0.4128, -0.4603,  0.3049, -0.1010, -0.0610,\n",
      "         0.0944,  0.0118,  0.2083, -0.0465,  0.4255, -0.1684,  0.3021,  0.6533,\n",
      "        -0.1711,  0.7927, -0.1805,  0.0251,  0.4587, -0.0898, -0.3824,  0.1191,\n",
      "        -0.1339, -0.0635,  0.1609,  0.3756,  0.7484, -0.3011, -0.6515,  0.7242,\n",
      "         0.6153,  0.0930, -0.0065, -0.5041,  0.0477,  0.2189,  0.1105,  0.0644,\n",
      "         0.0228, -0.0330, -0.2625, -0.0910, -0.0290, -0.4385,  0.5655, -0.5041,\n",
      "         0.3743, -0.2117,  0.0040, -0.0850, -0.3287, -0.6257,  0.2495,  0.0294,\n",
      "         0.0294, -0.3713,  0.0224,  0.5371,  0.1374, -0.0978,  0.0747, -0.2568,\n",
      "         0.1334, -0.2139,  0.2275,  0.0379,  0.1014, -0.2841, -0.0579, -0.6832,\n",
      "         0.1258, -0.6727, -0.5036,  0.2601, -0.0934,  0.0648, -0.3423, -0.0769,\n",
      "        -0.1659,  0.2316,  0.4822, -0.4422,  0.2343, -0.2196,  0.2903,  0.1184,\n",
      "        -0.7252,  0.2146,  0.5282,  0.4535, -0.0804,  0.3309, -0.0735,  0.1959,\n",
      "         0.1228, -0.2245, -0.3016,  0.0532,  0.4739, -0.4131,  0.0628, -0.2268,\n",
      "         0.1071, -0.0766,  0.4776, -0.3720,  0.4485,  0.4728,  0.7206,  0.4418,\n",
      "         0.0238, -0.6967, -0.3805, -0.4878,  0.3730, -0.1538, -0.1263, -0.3037,\n",
      "         0.1146,  0.4363, -0.3105,  0.0654, -0.4612, -0.1570, -0.2324, -0.3212,\n",
      "         0.0057, -0.1958, -0.3082, -0.2461, -0.2459,  0.2568, -0.5966,  0.1007,\n",
      "        -0.1647,  0.0944, -0.0786, -0.2146,  0.2650,  0.0197, -0.0692,  0.6366,\n",
      "         0.1370, -0.1309,  0.2299, -0.1640,  0.0026, -0.3839, -0.3796,  0.0247,\n",
      "         0.0374,  0.0869,  0.5813, -0.0597,  0.4290,  0.0614, -0.2834,  0.0031,\n",
      "         0.2302,  0.3882, -0.2861, -0.2103], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(z[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "z_relu_F = F.relu(z)\n",
    "z = z_relu_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randn(500,10)/np.sqrt(500)\n",
    "c.requires_grad_()\n",
    "\n",
    "c_zero = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -1.1852,   2.1445,   1.0576,   7.9334,  -9.7689,   2.8917,   4.5701,\n",
      "        -35.5101,  34.7942,  -2.7618], grad_fn=<SliceBackward>)\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "r = torch.matmul(z, c) + c_zero\n",
    "print(r[0,:])\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = F.softmax(r, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2849, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = F.cross_entropy(r, labels)\n",
    "print(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W,b,c,c_zero], lr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1cf6070d2f47568df77f932a953deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd2e857d4fd494f928712ec065a84cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1696c076c4491e9d068685794598a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb9fa5240224b4a95f589f2b12ec6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211c31527de04c2cab4385f70003d590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for images, labels in tqdm(train_loader):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = images.view(-1, 784)\n",
    "    z = torch.matmul(x, W) + b\n",
    "    z_relu_F = F.relu(z)\n",
    "    z = z_relu_F \n",
    "    r = torch.matmul(z, c) + c_zero    \n",
    "    cross_entropy = F.cross_entropy(r, labels)\n",
    "    \n",
    "    cross_entropy.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "for images, labels in tqdm(train_loader):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = images.view(-1, 784)\n",
    "    z = torch.matmul(x, W) + b\n",
    "    z_relu_F = F.relu(z)\n",
    "    z = z_relu_F \n",
    "    r = torch.matmul(z, c) + c_zero    \n",
    "    cross_entropy = F.cross_entropy(r, labels)\n",
    "    \n",
    "    cross_entropy.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "for images, labels in tqdm(train_loader):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = images.view(-1, 784)\n",
    "    z = torch.matmul(x, W) + b\n",
    "    z_relu_F = F.relu(z)\n",
    "    z = z_relu_F \n",
    "    r = torch.matmul(z, c) + c_zero    \n",
    "    cross_entropy = F.cross_entropy(r, labels)\n",
    "    \n",
    "    cross_entropy.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = images.view(-1, 784)\n",
    "    z = torch.matmul(x, W) + b\n",
    "    z_relu_F = F.relu(z)\n",
    "    z = z_relu_F \n",
    "    r = torch.matmul(z, c) + c_zero    \n",
    "    cross_entropy = F.cross_entropy(r, labels)\n",
    "    \n",
    "    cross_entropy.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = images.view(-1, 784)\n",
    "    z = torch.matmul(x, W) + b\n",
    "    z_relu_F = F.relu(z)\n",
    "    z = z_relu_F \n",
    "    r = torch.matmul(z, c) + c_zero    \n",
    "    cross_entropy = F.cross_entropy(r, labels)\n",
    "    \n",
    "    cross_entropy.backward()\n",
    "    optimizer.step() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7866eceedd2841178a8c9b64ae79c6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.9807)\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        x = images.view(-1, 784)\n",
    "        z = torch.matmul(x, W) + b\n",
    "        z_relu_F = F.relu(z)\n",
    "        z = z_relu_F\n",
    "        r = torch.matmul(z, c) + c_zero\n",
    "        \n",
    "        predictions = torch.argmax(r, dim=1)\n",
    "        correct += torch.sum((predictions==labels).float())\n",
    "        \n",
    "print(correct/total)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
